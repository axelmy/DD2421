{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed1014fd-22ca-46fa-8478-52315de31b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "tfk  = tf .keras\n",
    "tfkl = tfk.layers\n",
    "\n",
    "from utils import *\n",
    "from guided_ig import *\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import auc\n",
    "import pickle\n",
    "\n",
    "from tensorflow.python.ops import image_ops\n",
    "from tensorflow.python.ops import io_ops\n",
    "from tensorflow.python.keras.layers.preprocessing import image_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7494340-9b52-4eaf-b91a-70a4d0314155",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_xml = '/media/big/imagenet/data/ILSVRC/Annotations/CLS-LOC/val'\n",
    "p_jpg = '/media/big/imagenet/data/ILSVRC/Data/CLS-LOC/val'\n",
    "files_xml = sorted(os.listdir(p_xml))[:5000]\n",
    "files_jpg = sorted(os.listdir(p_jpg))[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f08900c-9a2f-4a55-a897-3be1007fb049",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet_class_index.json', 'r') as fp:\n",
    "    label_json = json.loads(fp.read())\n",
    "labels = np.array([\n",
    "    [k, *v]\n",
    "    for k, v in label_json.items()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a03771-275e-4201-b19a-67e8a579ed99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-08 23:11:39.036497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.044231: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.044615: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.045546: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-12-08 23:11:39.046024: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.046385: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.046728: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.405892: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.406173: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.406421: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-12-08 23:11:39.406652: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6992 MB memory:  -> device: 0, name: GeForce GTX 1080, pci bus id: 0000:02:00.0, compute capability: 6.1\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.applications.InceptionV3()\n",
    "def grad_func(x, idx):\n",
    "    x = tf.constant(x)[tf.newaxis]\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(x)\n",
    "        pred = model(x)\n",
    "        pred = pred[:, idx]\n",
    "    return np.squeeze(tape.gradient(pred, x).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ec4b394-aff2-420a-b50b-7c11a8e196c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]2021-12-08 23:11:53.675393: I tensorflow/stream_executor/cuda/cuda_dnn.cc:366] Loaded cuDNN version 8100\n",
      "2021-12-08 23:11:53.842423: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "p_save = '/media/big/imagenet/computed-gig'\n",
    "\n",
    "for f_xml, f_jpg in tqdm(zip(files_xml, files_jpg,\n",
    "                            # Comment to run\n",
    "                            #[]\n",
    "                            )): \n",
    "    with open(f'{p_xml}/{f_xml}') as fp:\n",
    "        xml = fp.read()\n",
    "\n",
    "    path = f'{p_jpg}/{f_jpg}'\n",
    "    img = io_ops.read_file(path)\n",
    "    img = image_ops.decode_image(\n",
    "        img, \n",
    "        channels = 3, \n",
    "        expand_animations = False\n",
    "    )\n",
    "    img = image_ops.resize_images_v2(\n",
    "        img, \n",
    "        (299, 299), \n",
    "        method = image_preprocessing.get_interpolation('bilinear')\n",
    "    )\n",
    "    img = preprocess_iv3(img)[0]\n",
    "    p5  = model(img[tf.newaxis]).numpy().flatten().argsort()[::-1][:5]\n",
    "    y   = xml.split('\\n')[13][8:-7]\n",
    "    \n",
    "    check_match = np.argwhere(labels[p5, 1] == y)\n",
    "    if len(check_match) > 0:\n",
    "        check_idx = p5[check_match][0, 0]\n",
    "        \n",
    "        # Guided IG\n",
    "        gig = np.stack([\n",
    "            unbounded_guided_ig(\n",
    "                img.numpy(),\n",
    "                baseline, \n",
    "                200, \n",
    "                lambda x: grad_func(x, check_idx), \n",
    "                0.1\n",
    "            )\n",
    "            for baseline in [\n",
    "                np.zeros_like(img) - 1, # To the model, black is -1\n",
    "                np.ones_like (img)      # White is 1\n",
    "            ]\n",
    "        ])\n",
    "        \n",
    "        # Anchored Guided IG (GIG(20))\n",
    "        gig20 = np.stack([\n",
    "            anchored_guided_ig(\n",
    "                img.numpy(),\n",
    "                baseline, \n",
    "                lambda x: grad_func(x, check_idx), \n",
    "                200, \n",
    "                0.1,\n",
    "                anchors = 20\n",
    "            )\n",
    "            for baseline in [\n",
    "                np.zeros_like(img) - 1,\n",
    "                np.ones_like (img)\n",
    "            ]\n",
    "        ])\n",
    "        res = np.concatenate([gig, gig20])\n",
    "        \n",
    "        with open(f'{p_save}/{f_xml}-{f_jpg}.pickle', 'wb') as fp:\n",
    "            pickle.dump({\n",
    "                'res': res,\n",
    "                'p5' : p5,\n",
    "                'y'  : y\n",
    "            }, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4bd7af2-9693-466b-a263-6e87cb4e3fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_plot(ax, xmin, xmax, ymin, ymax):\n",
    "    ax.plot([xmin, xmax], [ymin, ymin], 'r')\n",
    "    ax.plot([xmin, xmin], [ymin, ymax], 'r')\n",
    "    ax.plot([xmin, xmax], [ymax, ymax], 'r')\n",
    "    ax.plot([xmax, xmax], [ymin, ymax], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "89b49522-5f95-4f0e-88c3-16a652613fa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█████▎                                | 431/3100 [27:45<2:41:02,  3.62s/it]/tmp/ipykernel_4347/1580975637.py:124: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  auc_.append((FP / (FP + TN), TP / (TP + FN)))\n",
      "100%|█████████████████████████████████████| 3100/3100 [3:20:21<00:00,  3.88s/it]\n"
     ]
    }
   ],
   "source": [
    "inbox = lambda samples, xmin, xmax, ymin, ymax: (\n",
    "    (samples > [xmin, ymin]) & \n",
    "    (samples < [xmax, ymax])\n",
    ").all(1)\n",
    "\n",
    "idxs = np.array([\n",
    "    (idx, jdx)\n",
    "    for idx in range(299)\n",
    "    for jdx in range(299)\n",
    "])\n",
    "\n",
    "saved_res = os.listdir(p_save)\n",
    "ress = []\n",
    "for sr in tqdm(saved_res):\n",
    "    \n",
    "    xml, jpg = sr[:-7].split('-')\n",
    "    \n",
    "    xml = f'{p_xml}/{xml}'\n",
    "    jpg = f'{p_jpg}/{jpg}'\n",
    "    res = f'{p_save}/{sr}'\n",
    "    \n",
    "    with open(res, 'rb') as fp:\n",
    "        obj = pickle.load(fp)\n",
    "    \n",
    "    # Make sure that bounding box is actually available\n",
    "    if labels[obj['p5'][0], 1] == obj['y']:\n",
    "    \n",
    "        # Load image\n",
    "        img = io_ops.read_file(jpg)\n",
    "        img = image_ops.decode_image(\n",
    "            img, \n",
    "            channels = 3, \n",
    "            expand_animations = False\n",
    "        )\n",
    "        img = image_ops.resize_images_v2(\n",
    "            img, \n",
    "            (299, 299), \n",
    "            method = image_preprocessing.get_interpolation('bilinear')\n",
    "        )\n",
    "        img.set_shape((299, 299, 3))\n",
    "        img = tfk.applications.inception_v3.preprocess_input(img)\n",
    "\n",
    "        # Load BBOX\n",
    "        as_string = tf.io.read_file(xml)\n",
    "        vals = tf.gather(tf.strings.split(as_string, '\\n'), [7, 8, 18, 19, 20, 21])\n",
    "        vals = tf.strings.regex_replace(vals, '[^0123456789]', '')\n",
    "        vals = tf.strings.to_number(vals, tf.int32)\n",
    "\n",
    "        xmin, xmax, ymin, ymax = (\n",
    "            np.round(299 * vals[2] / vals[0]),\n",
    "            np.round(299 * vals[4] / vals[0]),\n",
    "            np.round(299 * vals[3] / vals[1]),\n",
    "            np.round(299 * vals[5] / vals[1]),\n",
    "        )\n",
    "        \n",
    "        # Compute IG\n",
    "        \n",
    "        best_idx   = obj['p5'][0]\n",
    "        image      = img[tf.newaxis]\n",
    "        baseline_b = tf.zeros_like(image) - 1\n",
    "        baseline_w = tf .ones_like(image)\n",
    "\n",
    "        steps = 200\n",
    "        batch = 25\n",
    "        igs   = []\n",
    "        for baseline in [baseline_b, baseline_w]:\n",
    "            delta  = (image - baseline) / steps\n",
    "            alpha  = tf.cast(tf.linspace(0, steps, steps)[:, tf.newaxis, tf.newaxis, tf.newaxis], tf.float32)\n",
    "            inputs = baseline + (alpha * delta)\n",
    "\n",
    "            ig = np.zeros_like(image)\n",
    "            pointer = 0\n",
    "            while pointer < steps:\n",
    "                inp = tf.gather(inputs, tf.range(pointer, pointer + batch))\n",
    "                with tf.GradientTape() as tape:\n",
    "                    tape.watch(inp)\n",
    "                    pred = model(inp)\n",
    "                    pred = pred[:, best_idx]\n",
    "                grad = tape.gradient(pred, inp)\n",
    "                ig += tf.reduce_sum(grad, 0).numpy()\n",
    "                pointer += batch\n",
    "            igs.append(ig)\n",
    "\n",
    "        # Prepare attributions\n",
    "        all_attr = (\n",
    "            obj['res'][0].mean(-1),           # GIG B\n",
    "            obj['res'][1].mean(-1),           # GIG W\n",
    "            obj['res'][[0, 1]].mean((0, -1)), # GIG B + W\n",
    "            obj['res'][2].mean(-1),           # GIG 20 B\n",
    "            obj['res'][3].mean(-1),           # GIG 20 W\n",
    "            obj['res'][[2, 3]].mean((0, -1)), # GIG 20 B + W\n",
    "            igs[0].mean((0, -1)),             # IG B\n",
    "            igs[1].mean((0, -1)),             # IG W\n",
    "            np.concatenate(igs).mean((0, -1)),# IG B + W \n",
    "            grad[-1].numpy().mean(-1),        # Gradient\n",
    "            (grad[-1] * img).numpy().mean(-1) # Gradient x Image\n",
    "        )\n",
    "\n",
    "        # Compute AUROC\n",
    "        qs = np.linspace(1, 0, 5)\n",
    "        res = []\n",
    "        for attr in all_attr:\n",
    "            auc_ = []\n",
    "            for q in qs:\n",
    "\n",
    "                positive_attr = np.concatenate([\n",
    "                    idxs, \n",
    "                    tf.gather_nd(attr, idxs).numpy()[:, np.newaxis]\n",
    "                ], 1)\n",
    "                positive_attr = positive_attr[positive_attr[:, 2] > 0]\n",
    "                \n",
    "                pos = np.argwhere(positive_attr[:, 2] >= np.quantile(positive_attr[:, 2], q)).flatten()\n",
    "                neg = np.argwhere(positive_attr[:, 2] <  np.quantile(positive_attr[:, 2], q)).flatten()\n",
    "                TP = inbox(positive_attr[pos, :2], xmin, xmax, ymin, ymax)\n",
    "                FP = ~TP\n",
    "                FN = inbox(positive_attr[neg, :2], xmin, xmax, ymin, ymax)\n",
    "                TN = ~FN\n",
    "\n",
    "                TP = TP.sum()\n",
    "                TN = TN.sum()\n",
    "                FP = FP.sum()\n",
    "                FN = FN.sum()\n",
    "                \n",
    "                auc_.append((FP / (FP + TN), TP / (TP + FN)))\n",
    "                \n",
    "            auc_ = np.array(auc_).T\n",
    "            res.append(auc(auc_[0], auc_[1]))\n",
    "            \n",
    "        ress.append(res)\n",
    "    \n",
    "        \n",
    "ress = pd.DataFrame(ress, columns = [\n",
    "    'GIG(0) (Black)',\n",
    "    'GIG(0) (White)',\n",
    "    'GIG(0) (B + W)',\n",
    "    'GIG(20) (White)',\n",
    "    'GIG(20) (Black)',\n",
    "    'GIG(20) (B + W)',\n",
    "    'IG (Black)',\n",
    "    'IG (White)',\n",
    "    'IG (Black + White)',\n",
    "    'Gradient',\n",
    "    'Gradient x Image'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c8d0f22a-008e-44e4-9cc7-3dc1d3434377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIG(0) (Black)</th>\n",
       "      <th>GIG(0) (White)</th>\n",
       "      <th>GIG(0) (B + W)</th>\n",
       "      <th>GIG(20) (White)</th>\n",
       "      <th>GIG(20) (Black)</th>\n",
       "      <th>GIG(20) (B + W)</th>\n",
       "      <th>IG (Black)</th>\n",
       "      <th>IG (White)</th>\n",
       "      <th>IG (Black + White)</th>\n",
       "      <th>Gradient</th>\n",
       "      <th>Gradient x Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2548.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2548.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>2550.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.633722</td>\n",
       "      <td>0.647112</td>\n",
       "      <td>0.650166</td>\n",
       "      <td>0.631799</td>\n",
       "      <td>0.634139</td>\n",
       "      <td>0.644910</td>\n",
       "      <td>0.630253</td>\n",
       "      <td>0.629399</td>\n",
       "      <td>0.631751</td>\n",
       "      <td>0.605682</td>\n",
       "      <td>0.586419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.110025</td>\n",
       "      <td>0.105562</td>\n",
       "      <td>0.107495</td>\n",
       "      <td>0.099853</td>\n",
       "      <td>0.103880</td>\n",
       "      <td>0.102716</td>\n",
       "      <td>0.097576</td>\n",
       "      <td>0.095306</td>\n",
       "      <td>0.096705</td>\n",
       "      <td>0.093833</td>\n",
       "      <td>0.095565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.185754</td>\n",
       "      <td>0.163102</td>\n",
       "      <td>0.168265</td>\n",
       "      <td>0.236575</td>\n",
       "      <td>0.181559</td>\n",
       "      <td>0.231746</td>\n",
       "      <td>0.237349</td>\n",
       "      <td>0.249118</td>\n",
       "      <td>0.236913</td>\n",
       "      <td>0.242713</td>\n",
       "      <td>0.217377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.560989</td>\n",
       "      <td>0.581348</td>\n",
       "      <td>0.580452</td>\n",
       "      <td>0.573533</td>\n",
       "      <td>0.571482</td>\n",
       "      <td>0.584462</td>\n",
       "      <td>0.574038</td>\n",
       "      <td>0.572563</td>\n",
       "      <td>0.573752</td>\n",
       "      <td>0.546212</td>\n",
       "      <td>0.526636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.639647</td>\n",
       "      <td>0.650414</td>\n",
       "      <td>0.656344</td>\n",
       "      <td>0.639480</td>\n",
       "      <td>0.643722</td>\n",
       "      <td>0.656327</td>\n",
       "      <td>0.633224</td>\n",
       "      <td>0.633024</td>\n",
       "      <td>0.635984</td>\n",
       "      <td>0.605109</td>\n",
       "      <td>0.586540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.710265</td>\n",
       "      <td>0.719867</td>\n",
       "      <td>0.724181</td>\n",
       "      <td>0.701026</td>\n",
       "      <td>0.706197</td>\n",
       "      <td>0.714177</td>\n",
       "      <td>0.692376</td>\n",
       "      <td>0.690881</td>\n",
       "      <td>0.693606</td>\n",
       "      <td>0.665088</td>\n",
       "      <td>0.650118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.883116</td>\n",
       "      <td>0.880170</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.881073</td>\n",
       "      <td>0.876854</td>\n",
       "      <td>0.860696</td>\n",
       "      <td>0.875525</td>\n",
       "      <td>0.871978</td>\n",
       "      <td>0.874498</td>\n",
       "      <td>0.866244</td>\n",
       "      <td>0.864503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       GIG(0) (Black)  GIG(0) (White)  GIG(0) (B + W)  GIG(20) (White)  \\\n",
       "count     2548.000000     2550.000000     2550.000000      2548.000000   \n",
       "mean         0.633722        0.647112        0.650166         0.631799   \n",
       "std          0.110025        0.105562        0.107495         0.099853   \n",
       "min          0.185754        0.163102        0.168265         0.236575   \n",
       "25%          0.560989        0.581348        0.580452         0.573533   \n",
       "50%          0.639647        0.650414        0.656344         0.639480   \n",
       "75%          0.710265        0.719867        0.724181         0.701026   \n",
       "max          0.883116        0.880170        0.883599         0.881073   \n",
       "\n",
       "       GIG(20) (Black)  GIG(20) (B + W)   IG (Black)   IG (White)  \\\n",
       "count      2550.000000      2550.000000  2550.000000  2550.000000   \n",
       "mean          0.634139         0.644910     0.630253     0.629399   \n",
       "std           0.103880         0.102716     0.097576     0.095306   \n",
       "min           0.181559         0.231746     0.237349     0.249118   \n",
       "25%           0.571482         0.584462     0.574038     0.572563   \n",
       "50%           0.643722         0.656327     0.633224     0.633024   \n",
       "75%           0.706197         0.714177     0.692376     0.690881   \n",
       "max           0.876854         0.860696     0.875525     0.871978   \n",
       "\n",
       "       IG (Black + White)     Gradient  Gradient x Image  \n",
       "count         2550.000000  2550.000000       2550.000000  \n",
       "mean             0.631751     0.605682          0.586419  \n",
       "std              0.096705     0.093833          0.095565  \n",
       "min              0.236913     0.242713          0.217377  \n",
       "25%              0.573752     0.546212          0.526636  \n",
       "50%              0.635984     0.605109          0.586540  \n",
       "75%              0.693606     0.665088          0.650118  \n",
       "max              0.874498     0.866244          0.864503  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ress.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "22ae212a-183e-4399-99e5-8bed0031957d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ress.to_csv('results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
